{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dbbd6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import numpy as np\n",
    "import requests\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import StepLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d871d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ebef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd416010",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784e634d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation_ID</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Phenophase_ID</th>\n",
       "      <th>Observation_Date</th>\n",
       "      <th>Abundance_Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>1795824</td>\n",
       "      <td>32.250660</td>\n",
       "      <td>-110.946358</td>\n",
       "      <td>489</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>6838318</td>\n",
       "      <td>32.250660</td>\n",
       "      <td>-110.946358</td>\n",
       "      <td>489</td>\n",
       "      <td>2015-12-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>2588139</td>\n",
       "      <td>32.212666</td>\n",
       "      <td>-111.001831</td>\n",
       "      <td>489</td>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8333</th>\n",
       "      <td>2588163</td>\n",
       "      <td>32.212666</td>\n",
       "      <td>-111.001831</td>\n",
       "      <td>489</td>\n",
       "      <td>2013-07-31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>2588187</td>\n",
       "      <td>32.212666</td>\n",
       "      <td>-111.001831</td>\n",
       "      <td>489</td>\n",
       "      <td>2013-08-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Observation_ID   Latitude   Longitude  Phenophase_ID Observation_Date  \\\n",
       "1754         1795824  32.250660 -110.946358            489       2013-01-28   \n",
       "1756         6838318  32.250660 -110.946358            489       2015-12-08   \n",
       "8332         2588139  32.212666 -111.001831            489       2013-07-23   \n",
       "8333         2588163  32.212666 -111.001831            489       2013-07-31   \n",
       "8334         2588187  32.212666 -111.001831            489       2013-08-06   \n",
       "\n",
       "      Abundance_Binary  \n",
       "1754                 1  \n",
       "1756                 1  \n",
       "8332                 1  \n",
       "8333                 1  \n",
       "8334                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('pheno-data.csv')\n",
    "df = df[(df['Phenophase_Description'] == 'Leaves (grasses)') & (df['Intensity_Value'] != '-9999')]\n",
    "df['Abundance_Binary'] = df['Intensity_Value'].apply(lambda x: 1 if x == '75-94%' or x == '50-74%' or x == '95% or more' else 0)\n",
    "df_filtered = df[['Observation_ID','Latitude', 'Longitude', 'Phenophase_ID', 'Observation_Date', 'Abundance_Binary']]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d3cfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1241/1698 [34:10<11:26,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1242/1698 [34:11<10:21,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1243/1698 [34:12<09:48,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1244/1698 [34:13<09:27,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1280/1698 [35:09<09:15,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1642/1698 [44:37<01:09,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1643/1698 [44:38<01:01,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1644/1698 [44:39<00:58,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1684/1698 [45:35<00:16,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1685/1698 [45:36<00:13,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ImageCollection.getRegion: No bands in collection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1698/1698 [45:52<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "all_ts_data = []\n",
    "labels = []\n",
    "evis = []\n",
    "\n",
    "scale = 100 # meters\n",
    "days = 25 \n",
    "\n",
    "label = df_filtered.Abundance_Binary.values\n",
    "\n",
    "for i in tqdm(range(len(df_filtered))):\n",
    "    end_date = df_filtered.Observation_Date.values[i]\n",
    "    start_date = (datetime.strptime(end_date, \"%Y-%m-%d\") - timedelta(days=days)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    lat = df_filtered.Latitude.values[i]\n",
    "    long = df_filtered.Longitude.values[i]\n",
    "    point = ee.Geometry.Point([long, lat])\n",
    "    \n",
    "    ## precipitation data\n",
    "    prec = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')\n",
    "    prec = prec.select('total_precipitation_sum')\n",
    "    prec = prec.filterDate(start_date, end_date)\n",
    "\n",
    "    ## land surface temperature data\n",
    "    lst = ee.ImageCollection('ECMWF/ERA5_LAND/DAILY_AGGR')\n",
    "    lst = lst.select('skin_temperature')\n",
    "    lst = lst.filterDate(start_date, end_date)\n",
    "\n",
    "    ## soil moisture data\n",
    "    soil_moisture = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n",
    "    soil_moisture = soil_moisture.select('volumetric_soil_water_layer_1')\n",
    "    soil_moisture = soil_moisture.filterDate(start_date, end_date)\n",
    "\n",
    "    ## EVI data (from MODIS)\n",
    "    evi = ee.ImageCollection('MODIS/006/MOD13A1')\n",
    "    evi = evi.select('EVI')\n",
    "    evi = evi.filterDate(start_date, end_date)\n",
    "\n",
    "    ## solar radiation data \n",
    "    solar_rad = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n",
    "    solar_rad = solar_rad.select('surface_solar_radiation_downwards_sum')\n",
    "    solar_rad = solar_rad.filterDate(start_date, end_date)\n",
    "\n",
    "    ## temperature data \n",
    "    temperature = ee.ImageCollection(\"ECMWF/ERA5_LAND/DAILY_AGGR\")\n",
    "    temperature = temperature.select('temperature_2m')\n",
    "    temperature = temperature.filterDate(start_date, end_date)\n",
    "    \n",
    "    try:\n",
    "        ts_prec = prec.getRegion(point, scale).getInfo()\n",
    "        ts_prec = [k[-1]*39.3701 if k[-1] is not None else 0 for k in ts_prec[1:]]\n",
    "\n",
    "        ts_lst = lst.getRegion(point, scale).getInfo()\n",
    "        ts_lst = [k[-1] - 273.15 if k[-1] is not None else 0 for k in ts_lst[1:]]  # -273.15 for Celsius\n",
    "        \n",
    "        ts_soil = soil_moisture.getRegion(point, scale).getInfo()\n",
    "        ts_soil = [k[-1] if k[-1] is not None else 0 for k in ts_soil[1:]]\n",
    "\n",
    "        ts_evi = evi.getRegion(point, scale).getInfo()\n",
    "        ts_evi = [k[-1]*0.0001 if k[-1] is not None else 0 for k in ts_evi[1:]]\n",
    "\n",
    "        ts_solar_rad = solar_rad.getRegion(point, scale).getInfo()\n",
    "        ts_solar_rad = [k[-1] if k[-1] is not None else 0 for k in ts_solar_rad[1:]]\n",
    "        \n",
    "        ts_temperature = temperature.getRegion(point, scale).getInfo()\n",
    "        ts_temperature = [k[-1] if k[-1] is not None else 0 for k in ts_temperature[1:]]\n",
    "\n",
    "        ts_combined = list(zip(ts_prec, ts_lst, ts_soil, ts_solar_rad, ts_temperature))\n",
    "        all_ts_data.append(ts_combined)\n",
    "        evis.append(ts_evi)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        # add zeros\n",
    "        all_ts_data.append([(0.0, 0.0, 0.0, 0.0, 0.0)] * 25)\n",
    "        evis.append(0)\n",
    "\n",
    "    labels.append(label[i])\n",
    "\n",
    "df_all_ts_data = pd.DataFrame.from_records(all_ts_data)\n",
    "df_all_ts_data['label'] = labels\n",
    "df_all_ts_data['evi'] = evis\n",
    "df_all_ts_data.to_csv('all_ts_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1195b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuffelLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(BuffelLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.hidden2out(lstm_out[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27f2cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "all_ts_data = np.array(all_ts_data)\n",
    "\n",
    "file_path = 'all_ts_data.pkl'\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        loaded_arr = pickle.load(f)\n",
    "else:\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(all_ts_data, f)\n",
    "\n",
    "all_ts_data = np.array([scaler.fit_transform(all_ts_data[i]) for i in range(len(all_ts_data))])\n",
    "all_ts_data = torch.FloatTensor(all_ts_data)\n",
    "labels = torch.FloatTensor(labels)\n",
    "\n",
    "labels = np.array(labels)\n",
    "labels = torch.FloatTensor(labels)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_ts_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "input_dim = 5 \n",
    "hidden_dim = 128\n",
    "\n",
    "model = BuffelLSTM(input_dim, hidden_dim)\n",
    "# note: here we are weighting the positive labels relative to their prevalence\n",
    "pos_weight = torch.tensor([(1 / labels.mean()) + 0.1]) \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "num_epochs = 200\n",
    "highest_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output.squeeze(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            preds = (output.squeeze() > 0.5).float() \n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(target.numpy())\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(all_preds, all_labels).ravel()\n",
    "    acc = 100 * (tn + tp) / len(all_labels)\n",
    "    fp_rate = 100 * fp / len(all_labels)\n",
    "    fn_rate = 100 * fn / len(all_labels)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}')\n",
    "    print(f'Accuracy: {acc}%')\n",
    "    print(f'FP: {fp_rate}%')\n",
    "    print(f'FN: {fn_rate}%')\n",
    "    \n",
    "    if acc > highest_acc:\n",
    "        highest_acc = acc\n",
    "        torch.save(model.state_dict(), \"highest_accuracy_model.pth\")\n",
    "        print(f\"New highest accuracy: {highest_acc}%. Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2420b0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BuffelLSTM(\n",
       "  (lstm): LSTM(5, 128, num_layers=2, batch_first=True)\n",
       "  (hidden2out): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load highest performing model\n",
    "best_model = BuffelLSTM(input_dim, hidden_dim)\n",
    "best_model.load_state_dict(torch.load(\"highest_accuracy_model.pth\"))\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f54df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.0%\n",
      "FP: 5.0%\n",
      "FN: 10.0%\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = best_model(data)\n",
    "        preds = (output.squeeze() > 0.5).float() \n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(target.numpy())\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(all_preds, all_labels).ravel()\n",
    "acc = 100 * (tn + tp) / len(all_labels)\n",
    "fp_rate = 100 * fp / len(all_labels)\n",
    "fn_rate = 100 * fn / len(all_labels)\n",
    "\n",
    "print(f'Accuracy: {acc}%')\n",
    "print(f'FP: {fp_rate}%')\n",
    "print(f'FN: {fn_rate}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80a688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6597d1ed23b894caf154b6750f098a8514a19e03807460ffd2d8425103778dc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
