{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41b252c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e4623ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuffelLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(BuffelLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=2, batch_first=True)\n",
    "        self.hidden2out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        output = self.hidden2out(lstm_out[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70179935",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "lr = 1e-4\n",
    "batch_size = 2\n",
    "hidden_dim = 128\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92d6c3",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d01518",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "train_data_path = '../buffelgrass-onetime-train.csv'\n",
    "test_data_path = '../buffelgrass-onetime-test.csv'\n",
    "train_feature_path = '../buffelgrass-onetime-train.npy'\n",
    "test_feature_path = '../buffelgrass-onetime-test.npy'\n",
    "variable_path = '../buffelgrass-onetime-variables.npy'\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "train_features = np.load(train_feature_path, allow_pickle=True).astype('float')\n",
    "test_features = np.load(test_feature_path, allow_pickle=True).astype('float')\n",
    "\n",
    "## labels\n",
    "train_labels = torch.FloatTensor(train_data.Abundance_Binary.values)\n",
    "test_labels = torch.from_numpy(test_data.Abundance_Binary.values)\n",
    "\n",
    "## precipitation feature\n",
    "train_features = torch.FloatTensor(train_features)\n",
    "test_features = torch.FloatTensor(test_features)\n",
    "\n",
    "## normalization\n",
    "mean, std = torch.mean(train_features), torch.std(train_features)\n",
    "train_features = ((train_features-mean)/std)\n",
    "test_features = (test_features-mean)/std\n",
    "\n",
    "## torch datasets\n",
    "test_dataset = TensorDataset(test_features, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e61015a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "Split: 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:26,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 48.38709677419355%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:02<01:26,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 54.83870967741935%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [00:16<01:12,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 58.064516129032256%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 20/100 [00:17<01:10,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 70.96774193548387%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:29<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.35897435897436%\n",
      "FP: 7.6923076923076925%\n",
      "FN: 17.94871794871795%\n",
      "---------------------\n",
      "Split: 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:25,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 64.51612903225806%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:28<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.282051282051285%\n",
      "FP: 48.717948717948715%\n",
      "FN: 0.0%\n",
      "---------------------\n",
      "Split: 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:22,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 51.61290322580645%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:20<01:04,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 67.74193548387096%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:25<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.35897435897436%\n",
      "FP: 5.128205128205129%\n",
      "FN: 20.512820512820515%\n",
      "---------------------\n",
      "Split: 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:26,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 54.83870967741935%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:21<01:08,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 67.74193548387096%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:32<00:53,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 70.96774193548387%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:36<00:49,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 74.19354838709677%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:29<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 77.41935483870968%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:30<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.66666666666667%\n",
      "FP: 25.641025641025642%\n",
      "FN: 7.6923076923076925%\n",
      "---------------------\n",
      "Split: 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<01:36,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 38.70967741935484%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:02<01:36,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 61.29032258064516%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 4/100 [00:03<01:34,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 64.51612903225806%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:28<01:04,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New highest accuracy: 70.96774193548387%. Model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:36<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.35897435897436%\n",
      "FP: 5.128205128205129%\n",
      "FN: 20.512820512820515%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "test_acc = []\n",
    "test_fp = []\n",
    "test_fn = []\n",
    "for i, (train_index, val_index) in enumerate(kf.split(train_features)):\n",
    "    \n",
    "    ## split\n",
    "    print('---------------------')\n",
    "    print(f'Split: {i+1}...')\n",
    "    val_features = train_features[val_index]\n",
    "    val_labels = train_labels[val_index]\n",
    "    train_sub_features = train_features[train_index]\n",
    "    train_sub_labels = train_labels[train_index]\n",
    "        \n",
    "    ## torch datasets\n",
    "    train_dataset = TensorDataset(train_sub_features, train_sub_labels)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = TensorDataset(val_features, val_labels)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    ## load model\n",
    "    model = BuffelLSTM(input_dim, hidden_dim)\n",
    "    pos_weight = torch.tensor([(1 / torch.cat([train_labels, test_labels]).float().mean()) + 0.1]) \n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    ## training\n",
    "    highest_acc = 0.0\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output.squeeze_(-1), target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "        ## evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in val_loader:\n",
    "                output = model(data)\n",
    "                preds = (output.squeeze_(-1) > 0.5).float() \n",
    "                all_preds.extend(preds.numpy())\n",
    "                all_labels.extend(target.numpy())\n",
    "        tn, fp, fn, tp = confusion_matrix(all_preds, all_labels).ravel()\n",
    "        acc = 100 * (tn + tp) / len(all_labels)       \n",
    "        if acc > highest_acc:\n",
    "            highest_acc = acc\n",
    "            torch.save(model.state_dict(), \"highest_accuracy_model.pth\")\n",
    "            print(f\"New highest accuracy: {highest_acc}%. Model saved.\")\n",
    "    \n",
    "    # load highest performing model\n",
    "    best_model = BuffelLSTM(input_dim, hidden_dim)\n",
    "    best_model.load_state_dict(torch.load(\"highest_accuracy_model.pth\"))    \n",
    "    best_model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = best_model(data)\n",
    "            preds = (output.squeeze_(-1) > 0.5).float() \n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_labels.extend(target.numpy())\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(all_preds, all_labels).ravel()\n",
    "    acc = 100 * (tn + tp) / len(all_labels)\n",
    "    fp_rate = 100 * fp / len(all_labels)\n",
    "    fn_rate = 100 * fn / len(all_labels)\n",
    "    \n",
    "    print(f'Accuracy: {acc}%')\n",
    "    print(f'FP: {fp_rate}%')\n",
    "    print(f'FN: {fn_rate}%')\n",
    "    test_acc.append(acc)\n",
    "    test_fp.append(fp_rate)\n",
    "    test_fn.append(fn_rate)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fd11594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68.2051282051282, 8.970695222838925)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_acc), np.std(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bcd7596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18.46153846153846, 16.961882470298693)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_fp), np.std(test_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31ffbfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.333333333333334, 8.17301407718422)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_fn), np.std(test_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
